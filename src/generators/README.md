# CSV Generator（測試資料產生器）

本目錄包含用於產生 **模擬電商交易資料（CSV）** 的工具，  
主要用途不是 demo，而是 **刻意製造「接近真實世界的資料問題」**，  
用來驗證：

- Dataset Overview 是否能抓到風險
- 分析圖表是否會被誤導
- 系統在大資料量下的效能與穩定性

> 如果這份 README 看起來有點「悲觀」，那是刻意的。  
> 真實世界的資料，比你想像得更糟。

---

## 為什麼需要這個 Generator？

在實務上，分析工具最常死在兩件事：

1. **資料太乾淨**
2. **測試資料過於理想**

這會導致：
- Overview 永遠顯示「一切正常」
- 分析結果看起來都很合理
- 直到接到第一份真實商家 CSV 才全面翻車

這個 generator 的目標是反過來：

> **讓資料「看起來合理，但其實藏雷」**

---

## 基本用法（Clean Mode）

預設產生的是「相對乾淨」的資料，適合用來：

- 壓測效能
- 驗證 schema
- 確認分析流程是否能跑完

```bash
python csv_generator.py \
  --rows 1000000 \
  --out clean.csv
```

### 主要特性
- 時間分佈連續
- 訂單 / 商品 / 會員比例合理
- 缺失值僅限於「合理缺失」（如未付款訂單）
- 幾乎沒有極端值

---

## Scenario A：分析師會不會被誤導（Skewed Reality）

Scenario A 的目標是模擬 **真實電商世界中常見的偏態行為**，  
資料本身沒有壞掉，但會讓分析結果開始變得「不那麼直覺」。

```bash
python csv_generator.py \
  --rows 1000000 \
  --out scenario_A.csv \
  --scenario A
```

### Scenario A 會引入的現象

#### A1. 活動日尖峰（Campaign Spikes）
- 隨機挑選 8～12 天作為活動日
- 約 10% 訂單集中在這些日期
- 每日訂單數趨勢會出現明顯 spike

👉 用來測試：
- Overview 是否能判斷資料是否為「活資料」
- 分析師是否會忽略活動影響而誤判趨勢

---

#### A2. 頭部商品（Power-law Products）
- 前 20 個商品獲得顯著較高曝光權重
- Top 商品佔比可達 30～50%

👉 用來測試：
- 熱門商品分析是否過度集中
- 平均值是否開始說謊

---

#### A3. 頭部會員（Heavy Buyers）
- 約 1% 會員貢獻 15～25% 訂單
- 訂單數 / 會員數比例變得不對稱

👉 用來測試：
- 會員分析是否被少數大戶扭曲
- 回購 / 客單分析是否需要分群

---

## 使用範例：Scenario A（真實偏態世界）

以下是一個**完整、可重現、實務導向**的使用流程範例，  
假設你現在的目標是：

> 驗證 Dataset Overview 是否能察覺  
> 「資料看起來合理，但其實存在偏態與誤導風險」。

---

### Step 1：產生 Scenario A 的測試資料

```bash
python csv_generator.py \
  --rows 1000000 \
  --out scenario_A.csv \
  --scenario A \
  --seed 42
```

說明：
- `--scenario A`：啟用偏態行為（活動日、頭部商品、大戶會員）
- `--rows`：產生 100 萬筆「訂單明細列」
- `--seed`：固定隨機種子，方便重現結果（很重要）

---

### Step 2：將 CSV 載入分析工具

將 `scenario_A.csv` 放入分析系統（例如本專案的 `/ui` 上傳流程），  
系統會產生一組 `analysis_id`，供後續 Overview 與 Analysis 使用。

---

### Step 3：使用 Dataset Overview 驗收（關鍵）

開啟：

```
/overview?analysis_id=xxx
```

在 Overview 中，你**應該刻意檢查以下現象**：

#### 1. 每日訂單數趨勢
- 是否出現 **8～12 個明顯尖峰日**
- 趨勢是否不再平滑

👉 若沒有尖峰，代表活動日權重不足。

---

#### 2. 資料規模區塊
- 訂單數 vs 會員數比例是否顯得「偏高」
- 是否開始出現「少數會員貢獻大量訂單」的直覺

👉 這是頭部會員（A3）的效果。

---

#### 3. 後續分析（非 Overview）
在分析頁（例如熱門商品、會員分析）中，應該可以觀察到：

- Top 商品佔比異常集中（A2）
- 平均值開始失真，需要分群或分段觀察

---

### Step 4：判斷工具是否「有感覺到怪」

Scenario A 的成功標準不是「資料看起來很亂」，  
而是你在使用 Overview 與分析頁時，開始出現這種感覺：

> 「這份資料好像哪裡怪怪的，需要小心解讀。」

如果完全沒有這種感覺，代表：
- 偏態權重還不夠
- 或 Overview 的提示還不夠明確

這正是下一步可以優化的地方。

---

### 常見用途整理

- 測試 Overview 是否能辨識「活動日影響」
- 驗證分析圖表是否容易被頭部商品／會員誤導
- 作為 Demo 資料，展示「為什麼不能只看平均值」

Scenario A 的目的不是製造錯誤資料，  
而是讓你看到 **「分析在真實世界會怎麼出事」**。

---

## 使用範例：Scenario B（資料可信度測試）

Scenario B 的目標不是讓資料「壞掉」，  
而是模擬 **真實世界中「看起來完整，但其實不值得完全信任」的資料狀態**。

這類資料最容易導致分析結果在事後被質疑，  
卻很難在第一時間被察覺。

---

### Step 1：產生 Scenario B 的測試資料

```bash
python csv_generator.py \
  --rows 1000000 \
  --out scenario_B.csv \
  --scenario B \
  --seed 42
```

或同時啟用偏態與可信度問題：

```bash
python csv_generator.py \
  --rows 1000000 \
  --out scenario_AB.csv \
  --scenario AB \
  --seed 42
```

---

### Step 2：將 CSV 載入分析工具

將 `scenario_B.csv` 或 `scenario_AB.csv` 上傳至系統，  
取得對應的 `analysis_id`。

---

### Step 3：使用 Dataset Overview 驗收（關鍵）

開啟：

```
/overview?analysis_id=xxx
```

在 Overview 中，請特別留意以下現象：

#### 1. 會員數的可信度
- 會員數看起來偏高
- 與訂單數的比例開始顯得不自然
- 系統目前不會直接標示錯誤，但應該讓你產生懷疑

👉 這通常來自 **非標準 member_id（空字串、unknown、test_user）** 的存在。

---

#### 2. 金額相關指標的不穩定感
- AOV、GMV 在分析頁可能出現難以解釋的波動
- 不同指標之間開始「對不起來」

👉 這來自 **少量訂單金額與明細加總不一致**，  
比例不高，但足以污染整體分析。

---

### Step 4：判斷 Overview 是否開始「提出質疑」

Scenario B 的成功標準不是看到紅色警告，  
而是你在解讀數字時出現這種反應：

> 「這些數字看起來都在，但我不太敢完全相信它們。」

如果完全沒有這種感覺，代表：
- 假資料比例可能太低
- 或 Overview 的提示語意還不夠明確

---

### 常見用途整理（Scenario B）

- 測試 Overview 是否能察覺「資料可信度問題」
- 驗證分析流程在資料不乾淨時是否仍具參考價值
- 作為內部教育素材，說明為何需要資料健檢

---

## 使用範例：Scenario C（時間欄位決策穩定性）

Scenario C 的目標是測試系統在 **歷史遷移與 schema 演進情境下**，  
是否仍能選擇「人類會選的時間欄位」進行分析。

---

### Step 1：產生 Scenario C 的測試資料

```bash
python csv_generator.py \
  --rows 1000000 \
  --out scenario_C.csv \
  --scenario C \
  --seed 42
```

或同時啟用偏態、資料可信度與時間遷移情境（最接近真實世界）：

```bash
python csv_generator.py \
  --rows 1000000 \
  --out scenario_ABC.csv \
  --scenario ABC \
  --seed 42
```

---

### Step 4：使用 Dataset Overview 驗收（關鍵）

開啟：

```
/overview?analysis_id=xxx
```

在 Overview 中，請確認以下行為：

#### 1. 主要時間欄位選擇
- 系統應優先選擇 `purchase_time` 作為主要時間欄位
- 不應因早期歷史資料而長期停留在 `created_at`

#### 2. 趨勢連續性
- 每日訂單數趨勢應跨越歷史切換點保持連續
- 不應在系統遷移期間出現「假斷層」

#### 3. 最近一筆交易判斷
- 應以實際可用時間欄位判斷最近交易
- 不應因某欄位在特定期間為空而誤判資料已過期

---

### Scenario C 的成功標準

Scenario C 並非要求「沒有問題」，  
而是：

> **即使資料本身混亂，Overview 仍能做出穩定、可理解的時間決策。**

---

### 常見用途整理（Scenario C）

- 測試時間欄位選擇邏輯的穩定性
- 驗證 datetime 探測策略在歷史資料下是否可靠
- 模擬系統遷移後的真實分析環境
- 驗證 Overview 在歷史資料混亂情境下是否仍具分析可信度

---

## 常用參數說明

| 參數 | 說明 |
|----|----|
| `--rows` | 產生的 **訂單明細列數**（不是訂單數） |
| `--out` | 輸出 CSV 檔案路徑 |
| `--scenario` | 資料情境：`clean`（預設）、`A` |
| `--members` | 模擬的會員總數 |
| `--products` | 模擬的商品總數 |
| `--chunk` | 寫檔批次大小（影響效能與記憶體） |
| `--seed` | 隨機種子（方便重現） |

---

## 驗收建議（非常重要）

每次產生資料後，**不要只看能不能跑完**，請務必用 Overview 驗收：

### Clean
- 趨勢平滑
- 沒有異常尖峰
- 數據看起來「太合理」

### Scenario A
- 每日訂單數有明顯 spike
- 熱門商品佔比異常集中
- 會員結構不再平均

如果 Scenario A 看起來還是「很舒服」，  
代表偏態還不夠狠，可以再調權重。

---

## 未來規劃（不要急）

- **Scenario B：資料品質雷**
  - 空字串 member_id
  - 重複 order_id
  - 金額不一致（order_total ≠ items sum）

- **Scenario C：系統遷移混亂（已實作）**
  - 不同時間段使用不同時間欄位
  - 某段時間 paid_at 全空
  - schema 在時間軸上不一致

這兩個 Scenario 的目的不是讓資料壞掉，  
而是讓 **資料「看起來還能用，但其實很危險」**。

---

## 一句提醒（寫給未來的自己）

> 如果某一份資料看起來「一切正常」，  
> 那它很可能只是還沒被真正使用。

這個 generator 的存在，就是為了戳破這件事。